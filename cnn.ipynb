{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a CPU.  If this is not desired, then the modify network3.py to set\n",
      "the GPU flag to True.\n",
      "A shallow net with 100 hidden neurons\n",
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 92.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 91.96%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 94.77%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 94.17%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 95.75%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.19%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 96.23%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.83%\n",
      "Training mini-batch number 20000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-db79566666c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[0mmini_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m \u001b[0mshallow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshallow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-78945b9a2bd9>\u001b[0m in \u001b[0;36mshallow\u001b[1;34m(n, epochs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         net.SGD(\n\u001b[0;32m    303\u001b[0m             \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             validation_data, test_data)\n\u001b[0m\u001b[0;32m    305\u001b[0m         \u001b[0mnets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-db79566666c5>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training mini-batch number {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                 \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                     validation_accuracy = np.mean(\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                 \u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_with_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexc_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# print a simple traceback from KeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 for thunk, node, old_storage in zip(self.thunks, self.nodes,\n\u001b[0;32m    299\u001b[0m                                                     self.post_thunk_clear):\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mold_s\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mold_storage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                         \u001b[0mold_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\tensor\\elemwise.py\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mnout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mufunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mufunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\scalar\\basic.py\u001b[0m in \u001b[0;36mimpl\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m   4022\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4023\u001b[0m         \u001b[0moutput_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4024\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4025\u001b[0m         ret = utils.to_return_values([storage[0] for storage in\n\u001b[0;32m   4026\u001b[0m                                       output_storage])\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\scalar\\basic.py\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[0;32m   4018\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4019\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimpl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4020\u001b[1;33m             \u001b[0mstorage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4022\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\scalar\\basic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   3890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3891\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3892\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproducers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3893\u001b[0m             \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3894\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\theano\\scalar\\basic.py\u001b[0m in \u001b[0;36mimpl\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1748\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1749\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mc_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\win7\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mproduct\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   1893\u001b[0m     \"\"\"\n\u001b[0;32m   1894\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1895\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1896\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keepdims'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import _pickle as cPickle\n",
    "import gzip\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "from theano.tensor.nnet import softmax\n",
    "from theano.tensor import shared_randomstreams\n",
    "from theano.tensor.signal import pool\n",
    "\n",
    "# Activation functions for neurons\n",
    "def linear(z): return z\n",
    "def ReLU(z): return T.maximum(0.0, z)\n",
    "from theano.tensor.nnet import sigmoid\n",
    "from theano.tensor import tanh\n",
    "\n",
    "\n",
    "#### Constants\n",
    "GPU = False\n",
    "if GPU:\n",
    "    print( \"Trying to run under a GPU.  If this is not desired, then modify \"+\\\n",
    "        \"network3.py\\nto set the GPU flag to False.\")\n",
    "    try: theano.config.device = 'gpu'\n",
    "    except: pass # it's already set\n",
    "    theano.config.floatX = 'float32'\n",
    "else:\n",
    "    print( \"Running with a CPU.  If this is not desired, then the modify \"+\\\n",
    "        \"network3.py to set\\nthe GPU flag to True.\")\n",
    "\n",
    "#### Load the MNIST data\n",
    "def load_data_shared():\n",
    "    f = gzip.open(r'C:\\Users\\win7\\Desktop\\New folder\\data\\mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = cPickle.load(f,encoding='iso-8859-1')\n",
    "    f.close()\n",
    "    def shared(data):\n",
    "    \n",
    "        shared_x = theano.shared(\n",
    "            np.asarray(data[0], dtype=theano.config.floatX), borrow=True)\n",
    "        shared_y = theano.shared(\n",
    "            np.asarray(data[1], dtype=theano.config.floatX), borrow=True)\n",
    "        return shared_x, T.cast(shared_y, \"int32\")\n",
    "    return [shared(training_data), shared(validation_data), shared(test_data)]\n",
    "\n",
    "#### Main class used to construct and train networks\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, layers, mini_batch_size):\n",
    "    \n",
    "        self.layers = layers\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.params = [param for layer in self.layers for param in layer.params]\n",
    "        self.x = T.matrix(\"x\")\n",
    "        self.y = T.ivector(\"y\")\n",
    "        init_layer = self.layers[0]\n",
    "        init_layer.set_inpt(self.x, self.x, self.mini_batch_size)\n",
    "        for j in range(1, len(self.layers)):\n",
    "            prev_layer, layer  = self.layers[j-1], self.layers[j]\n",
    "            layer.set_inpt(\n",
    "                prev_layer.output, prev_layer.output_dropout, self.mini_batch_size)\n",
    "        self.output = self.layers[-1].output\n",
    "        self.output_dropout = self.layers[-1].output_dropout\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            validation_data, test_data, lmbda=0.0):\n",
    "       \n",
    "        training_x, training_y = training_data\n",
    "        validation_x, validation_y = validation_data\n",
    "        test_x, test_y = test_data\n",
    "\n",
    "        # compute number of minibatches for training, validation and testing\n",
    "        num_training_batches = int(size(training_data)/mini_batch_size)\n",
    "        num_validation_batches = int(size(validation_data)/mini_batch_size)\n",
    "        num_test_batches = int(size(test_data)/mini_batch_size)\n",
    "\n",
    "        # define the (regularized) cost function, symbolic gradients, and updates\n",
    "        l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers])\n",
    "        cost = self.layers[-1].cost(self)+\\\n",
    "               0.5*lmbda*l2_norm_squared/num_training_batches\n",
    "        grads = T.grad(cost, self.params)\n",
    "        updates = [(param, param-eta*grad)\n",
    "                   for param, grad in zip(self.params, grads)]\n",
    "\n",
    "        # define functions to train a mini-batch, and to compute the\n",
    "        # accuracy in validation and test mini-batches.\n",
    "        i = T.lscalar() # mini-batch index\n",
    "        train_mb = theano.function(\n",
    "            [i], cost, updates=updates,\n",
    "            givens={\n",
    "                self.x:\n",
    "                training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        validate_mb_accuracy = theano.function(\n",
    "            [i], self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x:\n",
    "                validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        test_mb_accuracy = theano.function(\n",
    "            [i], self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x:\n",
    "                test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size],\n",
    "                self.y:\n",
    "                test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        self.test_mb_predictions = theano.function(\n",
    "            [i], self.layers[-1].y_out,\n",
    "            givens={\n",
    "                self.x:\n",
    "                test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size]\n",
    "            })\n",
    "        # Do the actual training\n",
    "        best_validation_accuracy = 0.0\n",
    "        for epoch in range(epochs):\n",
    "            for minibatch_index in range(num_training_batches):\n",
    "                iteration = num_training_batches*epoch+minibatch_index\n",
    "                if iteration % 1000 == 0:\n",
    "                    print(\"Training mini-batch number {0}\".format(iteration))\n",
    "                cost_ij = train_mb(minibatch_index)\n",
    "                if (iteration+1) % num_training_batches == 0:\n",
    "                    validation_accuracy = np.mean(\n",
    "                        [validate_mb_accuracy(j) for j in range(num_validation_batches)])\n",
    "                    print(\"Epoch {0}: validation accuracy {1:.2%}\".format(\n",
    "                        epoch, validation_accuracy))\n",
    "                    if validation_accuracy >= best_validation_accuracy:\n",
    "                        print(\"This is the best validation accuracy to date.\")\n",
    "                        best_validation_accuracy = validation_accuracy\n",
    "                        best_iteration = iteration\n",
    "                        if test_data:\n",
    "                            test_accuracy = np.mean(\n",
    "                                [test_mb_accuracy(j) for j in range(num_test_batches)])\n",
    "                            print('The corresponding test accuracy is {0:.2%}'.format(\n",
    "                                test_accuracy))\n",
    "        print(\"Finished training network.\")\n",
    "        print(\"Best validation accuracy of {0:.2%} obtained at iteration {1}\".format(\n",
    "            best_validation_accuracy, best_iteration))\n",
    "        print(\"Corresponding test accuracy of {0:.2%}\".format(test_accuracy))\n",
    "\n",
    "#### Define layer types\n",
    "\n",
    "class ConvPoolLayer(object):\n",
    "    \n",
    "\n",
    "    def __init__(self, filter_shape, image_shape, poolsize=(2, 2),\n",
    "                 activation_fn=sigmoid):\n",
    "       \n",
    "        self.filter_shape = filter_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.poolsize = poolsize\n",
    "        self.activation_fn=activation_fn\n",
    "        # initialize weights and biases\n",
    "        n_out = (filter_shape[0]*np.prod(filter_shape[2:])/np.prod(poolsize))\n",
    "        self.w = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=np.sqrt(1.0/n_out), size=filter_shape),\n",
    "                dtype=theano.config.floatX),\n",
    "            borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=1.0, size=(filter_shape[0],)),\n",
    "                dtype=theano.config.floatX),\n",
    "            borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape(self.image_shape)\n",
    "        conv_out = conv.conv2d(\n",
    "            input=self.inpt, filters=self.w, filter_shape=self.filter_shape,\n",
    "            image_shape=self.image_shape)\n",
    "        pooled_out = pool.pool_2d(\n",
    "            input=conv_out, ds=self.poolsize, ignore_border=True)\n",
    "        self.output = self.activation_fn(\n",
    "            pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n",
    "        self.output_dropout = self.output # no dropout in the convolutional layers\n",
    "\n",
    "class FullyConnectedLayer(object):\n",
    "\n",
    "    def __init__(self, n_in, n_out, activation_fn=sigmoid, p_dropout=0.0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.activation_fn = activation_fn\n",
    "        self.p_dropout = p_dropout\n",
    "        # Initialize weights and biases\n",
    "        self.w = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(\n",
    "                    loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)),\n",
    "                dtype=theano.config.floatX),\n",
    "            name='w', borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)),\n",
    "                       dtype=theano.config.floatX),\n",
    "            name='b', borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = self.activation_fn(\n",
    "            (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.inpt_dropout = dropout_layer(\n",
    "            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)\n",
    "        self.output_dropout = self.activation_fn(\n",
    "            T.dot(self.inpt_dropout, self.w) + self.b)\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        \n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "class SoftmaxLayer(object):\n",
    "\n",
    "    def __init__(self, n_in, n_out, p_dropout=0.0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.p_dropout = p_dropout\n",
    "        # Initialize weights and biases\n",
    "        self.w = theano.shared(\n",
    "            np.zeros((n_in, n_out), dtype=theano.config.floatX),\n",
    "            name='w', borrow=True)\n",
    "        self.b = theano.shared(\n",
    "            np.zeros((n_out,), dtype=theano.config.floatX),\n",
    "            name='b', borrow=True)\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def set_inpt(self, inpt, inpt_dropout, mini_batch_size):\n",
    "        self.inpt = inpt.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = softmax((1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.inpt_dropout = dropout_layer(\n",
    "            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)\n",
    "        self.output_dropout = softmax(T.dot(self.inpt_dropout, self.w) + self.b)\n",
    "\n",
    "    def cost(self, net):\n",
    "        \n",
    "        return -T.mean(T.log(self.output_dropout)[T.arange(net.y.shape[0]), net.y])\n",
    "\n",
    "    def accuracy(self, y):\n",
    "       \n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "\n",
    "#### Miscellanea\n",
    "def size(data):\n",
    "   \n",
    "    return data[0].get_value(borrow=True).shape[0]\n",
    "\n",
    "def dropout_layer(layer, p_dropout):\n",
    "    srng = shared_randomstreams.RandomStreams(\n",
    "        np.random.RandomState(0).randint(999999))\n",
    "    mask = srng.binomial(n=1, p=1-p_dropout, size=layer.shape)\n",
    "    return layer*T.cast(mask, theano.config.floatX)\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "\n",
    "training_data, validation_data, test_data = load_data_shared()\n",
    "mini_batch_size = 10\n",
    "shallow()\n",
    "\n",
    "def shallow(n=3, epochs=60):\n",
    "    nets = []\n",
    "    for j in range(n):\n",
    "        print( \"A shallow net with 100 hidden neurons\")\n",
    "        net = Network([\n",
    "            FullyConnectedLayer(n_in=784, n_out=100),\n",
    "            SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "        net.SGD(\n",
    "            training_data, epochs, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)\n",
    "        nets.append(net)\n",
    "    return nets \n",
    "\n",
    "def basic_conv(n=3, epochs=60):\n",
    "    for j in range(n):\n",
    "        print( \"Conv + FC architecture\")\n",
    "        net = Network([\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                          filter_shape=(20, 1, 5, 5), \n",
    "                          poolsize=(2, 2)),\n",
    "            FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
    "            SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "        net.SGD(\n",
    "            training_data, epochs, mini_batch_size, 0.1, validation_data, test_data)\n",
    "    return net \n",
    "\n",
    "def omit_FC():\n",
    "    for j in range(3):\n",
    "        print (\"Conv only, no FC\")\n",
    "        net = Network([\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                          filter_shape=(20, 1, 5, 5), \n",
    "                          poolsize=(2, 2)),\n",
    "            SoftmaxLayer(n_in=20*12*12, n_out=10)], mini_batch_size)\n",
    "        net.SGD(training_data, 60, mini_batch_size, 0.1, validation_data, test_data)\n",
    "    return net \n",
    "\n",
    "\n",
    "\n",
    "#### Some subsequent functions may make use of the expanded MNIST\n",
    "#### data.  That can be generated by running expand_mnist.py.\n",
    "\n",
    "def expanded_data(n=100):\n",
    "    \"\"\"n is the number of neurons in the fully-connected layer.  We'll try\n",
    "    n=100, 300, and 1000.\n",
    "\n",
    "    \"\"\"\n",
    "    expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"../data/mnist_expanded.pkl.gz\")\n",
    "    for j in range(3):\n",
    "        print(\"Training with expanded data, %s neurons in the FC layer, run num %s\" % (n, j))\n",
    "        net = Network([\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                          filter_shape=(20, 1, 5, 5), \n",
    "                          poolsize=(2, 2), \n",
    "                          activation_fn=ReLU),\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                          filter_shape=(40, 20, 5, 5), \n",
    "                          poolsize=(2, 2), \n",
    "                          activation_fn=ReLU),\n",
    "            FullyConnectedLayer(n_in=40*4*4, n_out=n, activation_fn=ReLU),\n",
    "            SoftmaxLayer(n_in=n, n_out=10)], mini_batch_size)\n",
    "        net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
    "                validation_data, test_data, lmbda=0.1)\n",
    "    return net \n",
    "\n",
    "def expanded_data_double_fc(n=100):\n",
    "    \"\"\"n is the number of neurons in both fully-connected layers.  We'll\n",
    "    try n=100, 300, and 1000.\n",
    "\n",
    "    \"\"\"\n",
    "    expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"../data/mnist_expanded.pkl.gz\")\n",
    "    for j in range(3):\n",
    "        print(\"Training with expanded data, %s neurons in two FC layers, run num %s\" % (n, j))\n",
    "        net = Network([\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                          filter_shape=(20, 1, 5, 5), \n",
    "                          poolsize=(2, 2), \n",
    "                          activation_fn=ReLU),\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                          filter_shape=(40, 20, 5, 5), \n",
    "                          poolsize=(2, 2), \n",
    "                          activation_fn=ReLU),\n",
    "            FullyConnectedLayer(n_in=40*4*4, n_out=n, activation_fn=ReLU),\n",
    "            FullyConnectedLayer(n_in=n, n_out=n, activation_fn=ReLU),\n",
    "            SoftmaxLayer(n_in=n, n_out=10)], mini_batch_size)\n",
    "        net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
    "                validation_data, test_data, lmbda=0.1)\n",
    "\n",
    "def double_fc_dropout(p0, p1, p2, repetitions):\n",
    "    expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"../data/mnist_expanded.pkl.gz\")\n",
    "    nets = []\n",
    "    for j in range(repetitions):\n",
    "        print(\"\\n\\nTraining using a dropout network with parameters \",p0,p1,p2)\n",
    "        print(\"Training with expanded data, run num %s\" % j)\n",
    "        net = Network([\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                          filter_shape=(20, 1, 5, 5), \n",
    "                          poolsize=(2, 2), \n",
    "                          activation_fn=ReLU),\n",
    "            ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                          filter_shape=(40, 20, 5, 5), \n",
    "                          poolsize=(2, 2), \n",
    "                          activation_fn=ReLU),\n",
    "            FullyConnectedLayer(\n",
    "                n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=p0),\n",
    "            FullyConnectedLayer(\n",
    "                n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=p1),\n",
    "            SoftmaxLayer(n_in=1000, n_out=10, p_dropout=p2)], mini_batch_size)\n",
    "        net.SGD(expanded_training_data, 40, mini_batch_size, 0.03, \n",
    "                validation_data, test_data)\n",
    "        nets.append(net)\n",
    "    return nets\n",
    "\n",
    "def ensemble(nets): \n",
    "    \n",
    "    test_x, test_y = test_data\n",
    "    for net in nets:\n",
    "        i = T.lscalar() # mini-batch index\n",
    "        net.test_mb_predictions = theano.function(\n",
    "            [i], net.layers[-1].y_out,\n",
    "            givens={\n",
    "                net.x: \n",
    "                test_x[i*net.mini_batch_size: (i+1)*net.mini_batch_size]\n",
    "            })\n",
    "        net.test_predictions = list(np.concatenate(\n",
    "            [net.test_mb_predictions(i) for i in range(1000)]))\n",
    "    all_test_predictions = zip(*[net.test_predictions for net in nets])\n",
    "    def plurality(p): return Counter(p).most_common(1)[0][0]\n",
    "    plurality_test_predictions = [plurality(p) \n",
    "                                  for p in all_test_predictions]\n",
    "    test_y_eval = test_y.eval()\n",
    "    error_locations = [j for j in range(10000) \n",
    "                       if plurality_test_predictions[j] != test_y_eval[j]]\n",
    "    erroneous_predictions = [plurality(all_test_predictions[j])\n",
    "                             for j in error_locations]\n",
    "    print(\"Accuracy is {:.2%}\".format((1-len(error_locations)/10000.0)))\n",
    "    return error_locations, erroneous_predictions\n",
    "\n",
    "def plot_errors(error_locations, erroneous_predictions=None):\n",
    "    test_x, test_y = test_data[0].eval(), test_data[1].eval()\n",
    "    fig = plt.figure()\n",
    "    error_images = [np.array(test_x[i]).reshape(28, -1) for i in error_locations]\n",
    "    n = min(40, len(error_locations))\n",
    "    for j in range(n):\n",
    "        ax = plt.subplot2grid((5, 8), (j/8, j % 8))\n",
    "        ax.matshow(error_images[j], cmap = matplotlib.cm.binary)\n",
    "        ax.text(24, 5, test_y[error_locations[j]])\n",
    "        if erroneous_predictions:\n",
    "            ax.text(24, 24, erroneous_predictions[j])\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    \n",
    "def plot_filters(net, layer, x, y):\n",
    "\n",
    "    filters = net.layers[layer].w.eval()\n",
    "    fig = plt.figure()\n",
    "    for j in range(len(filters)):\n",
    "        ax = fig.add_subplot(y, x, j)\n",
    "        ax.matshow(filters[j][0], cmap = matplotlib.cm.binary)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "#### Helper method to run all experiments in the book\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
